{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Biblioteca\n",
    "# =============================================================================\n",
    "import time     # Facilita desenvolvimento envolvendo tempo, tempo de espera, etc\n",
    "import pandas as pd\n",
    "import glob # busca de arquivos em um diretório usando padrões de nome de arquivo.\n",
    "import os\n",
    "import shutil #Para mover um arquivo para outra pasta, você pode usar a função shutil.move() do módulo shutil.\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import unidecode #acento \n",
    "import np\n",
    "#import numpy as np\n",
    "import numpy as np\n",
    "from hdbcli import dbapi\n",
    "\n",
    "# pip install hdbcli --proxy=http://array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Funções internas\n",
    "# =============================================================================\n",
    "sys.path.insert(1, '../wfuncoes py')\n",
    "import keys as wk\n",
    "import excel as we\n",
    "import hana as wh\n",
    "log = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baixar os arquivos GA.txt e GB.txt no SAP e salvar na pasta\n",
    "#### Grupo A\n",
    "- EANLH\n",
    "- WEL_INST2\n",
    "- Classe de cálculo: A\n",
    "- Salvar GA.txt\n",
    "\n",
    "#### Grupo B\n",
    "- EANLH\n",
    "- WEL_INST2\n",
    "- Classe de cálculo: B \n",
    "- Mru: +++++T*\n",
    "    - Alternativa para SAP lento: \n",
    "    - SELECT ZCGINSTAL INSTALACAO FROM CLB961851.PLANILHAO_CLIENTE WHERE SEQCC= 1 AND SUBSTRING(ZCGUNLEIT,6,1) = 'T'AND LEFT(ZCGTARTYP,1) = 'B'\n",
    "- Salvar GB.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Carregar arquivo GA\n",
    "path = \"C:\\\\Users\\\\u461539\\\\OneDrive - IBERDROLA S.A\\\\005.Scripts\\\\ga_cliente\\\\INPUT\\\\1.GA.txt\"\n",
    "df = pd.read_csv(path, delimiter='|', skiprows=3, dtype={'Instalação': str, 'UnLeit. ': str})\n",
    "df.columns = df.columns.str.strip() # Remover espaços em branco dos nomes das colunas\n",
    "df = df.drop(columns=['Unnamed: 0', 'Unnamed: 8','Válido até']) # Remover colunas indesejadas\n",
    "df = df.dropna(how='all') #excluir NaN\n",
    "df['Instalação'] = df['Instalação'].astype(int) # coluna instalacao inteiro\n",
    "df['Vál.desde'] = pd.to_datetime(df['Vál.desde'], format='%d.%m.%Y', errors='coerce')\n",
    "\n",
    "result = df\n",
    "\n",
    "# Carregar arquivo GB\n",
    "path = \"C:\\\\Users\\\\u461539\\\\OneDrive - IBERDROLA S.A\\\\005.Scripts\\\\ga_cliente\\\\INPUT\\\\2.GB.txt\"\n",
    "df = pd.read_csv(path, delimiter='|', skiprows=3, dtype={'Instalação': str, 'UnLeit. ': str})\n",
    "df.columns = df.columns.str.strip() # Remover espaços em branco dos nomes das colunas\n",
    "df = df.drop(columns=['Unnamed: 0', 'Unnamed: 8','Válido até']) # Remover colunas indesejadas\n",
    "df = df.dropna(how='all') #excluir NaN\n",
    "df['Instalação'] = df['Instalação'].astype(int) # coluna instalacao inteiro\n",
    "df['Vál.desde'] = pd.to_datetime(df['Vál.desde'], format='%d.%m.%Y', errors='coerce')\n",
    "\n",
    "result = pd.concat([result, df], ignore_index=True) # Adicionar as linhas\n",
    "result = result.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x) # Remover espaços após as palavras\n",
    "result.columns = [unidecode.unidecode(col).lower().replace('.', '') for col in result.columns] #renomear as colunas: acento, minuscula\n",
    "result.insert(0, 'dt_ref', datetime.now().strftime('%Y-%m-%d')) # Adicionar a data de hoje como a primeira coluna\n",
    "result.rename(columns={'valdesde': 'dt_inst_desde','ctgtar':'ctg_tar','setindus':'set_indus','clcal':'cl_cal','unleit':'mru'}, inplace=True)\n",
    "\n",
    "#coluna MRU\n",
    "def determine_mru(mru):\n",
    "    if mru[5] == 'T':\n",
    "        return 'Telemedido'\n",
    "    elif mru[5] == 'L':\n",
    "        return 'Livre'\n",
    "    elif mru.startswith('PR') or mru.startswith('TR'):\n",
    "        return 'Transitorio'\n",
    "    return 'Manual'\n",
    "result['mru_status'] = result['mru'].apply(determine_mru)\n",
    "\n",
    "#coluna grupo Cliente\n",
    "def determine_grupo(ctg_tar):\n",
    "    if ctg_tar.endswith('GR') or ctg_tar.endswith('CC'):\n",
    "        return 'Fronteira'\n",
    "    elif ctg_tar.endswith('LV'):\n",
    "        return 'Livre'\n",
    "    return 'Cativo'\n",
    "result['grupo_cliente'] = result['ctg_tar'].apply(determine_grupo)\n",
    "\n",
    "result = result.sort_values(by=['grupo_cliente', 'instalacao']) #ordenar\n",
    "\n",
    "#exportar instalações cativas para pegar a CC\n",
    "export = result[result['grupo_cliente'] == 'Cativo']['instalacao'].tolist()\n",
    "with open('OUTPUT\\\\instalacao_cativo.txt', 'w') as f:\n",
    "    for instalacao in export:\n",
    "        f.write(f\"{instalacao}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CCS: CC ATIVO\n",
    "- ZCV_EANLA\n",
    "- WEL_INST15\n",
    "- Input instalacao_cativo.txt\n",
    "- Salve CC.txt\n",
    "\n",
    "### Run CCS: Liminar\n",
    "- ZCV_EANLA\n",
    "- WEL_LIMINAR\n",
    "- Input instalacao_cativo.txt\n",
    "- Salve Liminar.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar arquivo CC\n",
    "path = \"C:\\\\Users\\\\u461539\\\\OneDrive - IBERDROLA S.A\\\\005.Scripts\\\\ga_cliente\\\\INPUT\\\\3.CC.txt\"\n",
    "df = pd.read_csv(path, delimiter='|', skiprows=3, dtype={'Instalação': str,'Cta.contr.': str,'ParcNeg.  ': str})\n",
    "df = df.drop(columns=['Unnamed: 0', 'Unnamed: 5','DtSolDesl.' ]) # Remover colunas indesejadas\n",
    "df.columns = df.columns.str.strip() # Remover espaços em branco dos nomes das colunas\n",
    "df.columns = [unidecode.unidecode(col).lower().replace('.', '') for col in df.columns] #renomear as colunas: acento, minuscula\n",
    "df = df.dropna(how='all') #excluir NaN\n",
    "df.rename(columns={'ctacontr': 'conta_contrato','parcneg': 'PN'}, inplace=True)\n",
    "df['instalacao'] = df['instalacao'].astype(int)\n",
    "df = df.sort_values(by=['instalacao']) #ordenar\n",
    "\n",
    "#Evitar duplicação\n",
    "coluna_para_excluir = ['conta_contrato','PN']\n",
    "for coluna in coluna_para_excluir:\n",
    "    if coluna in result.columns:\n",
    "        result = result.drop(columns=[coluna])\n",
    "        \n",
    "#Combinar dados\n",
    "result = pd.merge(result, df, on='instalacao', how='left')\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Carregar as Liminares\n",
    "path = \"C:\\\\Users\\\\u461539\\\\OneDrive - IBERDROLA S.A\\\\005.Scripts\\\\ga_cliente\\\\INPUT\\\\4.liminar.txt\"\n",
    "df = pd.read_csv(path, delimiter='|', skiprows=3)\n",
    "df = df.drop(columns=['Unnamed: 0', 'InstPrinc.','Funç.','Unnamed: 4' ]) # Remover colunas indesejadas\n",
    "df.columns = [unidecode.unidecode(col).lower().replace('.', '') for col in df.columns] #renomear as colunas: acento, minuscula\n",
    "df.columns = df.columns.str.strip() # Remover espaços em branco dos nomes das colunas\n",
    "df = df.dropna(how='all') #excluir NaN\n",
    "df['instalacao'] = df['instalacao'].astype(int)\n",
    "\n",
    "\n",
    "# Função para determinar o status\n",
    "def determinar_status(row):\n",
    "    if row['instalacao'] in df['instalacao'].values:\n",
    "        return 'Liminar'\n",
    "    elif pd.notnull(row['conta_contrato']):\n",
    "        return 'Ativo'\n",
    "    else:\n",
    "        return 'Baixado/Sem CC'\n",
    "\n",
    "# Aplicar a função ao dataframe para criar a nova coluna 'Status'\n",
    "result['status_cliente'] = result.apply(determinar_status, axis=1)\n",
    "result = result.sort_values(by=['status_cliente']) #ordenar\n",
    "\n",
    "#exportar instalações ativas para pegar o registrador lógico \n",
    "export = result[result['status_cliente'] == 'Ativo']['instalacao'].tolist()\n",
    "with open('OUTPUT\\\\instalacao_ativo.txt', 'w') as f:\n",
    "    for instalacao in export:\n",
    "        f.write(f\"{instalacao}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CCS: Registrador Lógico\n",
    "- EASTS\n",
    "- WEL_REG_LOG\n",
    "- Input instalacao_ativo.txt\n",
    "- Salve RL.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar Reg Lógicos\n",
    "path = \"C:\\\\Users\\\\u461539\\\\OneDrive - IBERDROLA S.A\\\\005.Scripts\\\\ga_cliente\\\\INPUT\\\\5.reglog.txt\"\n",
    "df = pd.read_csv(path, delimiter='|', skiprows=3, dtype={'Instalação': str,'   Nº registr.lóg.': str})\n",
    "df.columns = [unidecode.unidecode(col).lower().replace('.', '') for col in df.columns] #renomear as colunas: acento, minuscula\n",
    "df.columns = df.columns.str.strip() # Remover espaços em branco dos nomes das colunas\n",
    "df = df.drop(columns=['unnamed: 0', 'valdesde','unnamed: 4' ]) # Remover colunas indesejadas\n",
    "df.rename(columns={'no registrlog': 'reg_log'}, inplace=True)\n",
    "df = df.dropna(how='all') #excluir NaN\n",
    "df['instalacao'] = df['instalacao'].astype(int)\n",
    "\n",
    "#Evitar duplicação\n",
    "coluna_para_excluir = 'reg_log'\n",
    "if coluna_para_excluir in result.columns:\n",
    "    result = result.drop(columns=[coluna_para_excluir])\n",
    "#Combinar dados\n",
    "result = pd.merge(result, df, on='instalacao', how='left')\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Função para determinar o status\n",
    "def determinar_status(row):\n",
    "    if row['status_cliente'] == 'Liminar':\n",
    "        return 'Liminar'\n",
    "    elif row['status_cliente'] == 'Baixado/Sem CC':\n",
    "        return 'Baixado/Sem CC'\n",
    "    elif (row['status_cliente'] == 'Ativo' and pd.notnull(row['reg_log'])):\n",
    "        return 'Ativo'\n",
    "    elif (row['status_cliente'] == 'Ativo' and pd.isnull(row['reg_log'])):\n",
    "        return 'Ativo s/ RegLog'\n",
    "    else:\n",
    "        return 'Erro'\n",
    "\n",
    "# Aplicar a função ao dataframe para criar a nova coluna 'Status'\n",
    "result['status_cliente'] = result.apply(determinar_status, axis=1)\n",
    "result = result.sort_values(by=['status_cliente']) #ordenar\n",
    "\n",
    "#exportar instalações ativas para pegar o registrador lógico \n",
    "export = result[result['status_cliente'] == 'Ativo']['reg_log'].tolist()\n",
    "with open('OUTPUT\\\\reg_log.txt', 'w') as f:\n",
    "    for instalacao in export:\n",
    "        f.write(f\"{instalacao}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CCS: equi_log, fat_reg, em_desde\n",
    "- ETDZ\n",
    "- VL_EQUI\n",
    "- Input reg_log.txt\n",
    "- Salve equi.txt\n",
    "\n",
    "### Run CCS: fat_calc, tp_medicao\n",
    "- EZUZ\n",
    "- VL_FATCALC\n",
    "- Input reg_log.txt\n",
    "- Salve fat_calc.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar Equi_log, Fat_reg, EM_desde \n",
    "path = \"C:\\\\Users\\\\u461539\\\\OneDrive - IBERDROLA S.A\\\\005.Scripts\\\\ga_cliente\\\\INPUT\\\\6.equi.txt\"\n",
    "df = pd.read_csv(path, delimiter='|', skiprows=3, dtype={'Equipamento       ': str, '   Nº registr.lóg.': str})\n",
    "df.columns = [unidecode.unidecode(col).lower().replace('.', '') for col in df.columns] #renomear as colunas: acento, minuscula\n",
    "df.columns = df.columns.str.strip() # Remover espaços em branco dos nomes das colunas\n",
    "df = df.drop(columns=['unnamed: 0', 'valido ate','tpreg','ca','um','unnamed: 9' ]) # Remover colunas indesejadas\n",
    "df.rename(columns={'no registrlog': 'reg_log','equipamento': 'equi_log','valdesde': 'dt_em_desde','fatreg':'fat_reg'}, inplace=True)\n",
    "df['dt_em_desde'] = pd.to_datetime(df['dt_em_desde'])\n",
    "df['fat_reg'] = df['fat_reg'].str.replace(',', '.').str.strip().astype(float)\n",
    "df = df.dropna(how='all') #excluir NaN\n",
    "\n",
    "#Evitar duplicação\n",
    "coluna_para_excluir = ['equi_log','dt_em_desde','fat_reg']\n",
    "for coluna in coluna_para_excluir:\n",
    "    if coluna in result.columns:\n",
    "        result = result.drop(columns=[coluna])\n",
    "#Combinar dados\n",
    "result = pd.merge(result, df, on='reg_log', how='left')\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Carregar fat_calc, tp_medicao\n",
    "path = \"C:\\\\Users\\\\u461539\\\\OneDrive - IBERDROLA S.A\\\\005.Scripts\\\\ga_cliente\\\\INPUT\\\\7.fat_calc.txt\"\n",
    "df = pd.read_csv(path, delimiter='|', skiprows=3, dtype={'   Nº registr.lóg.': str})\n",
    "df.columns = [unidecode.unidecode(col).lower().replace('.', '') for col in df.columns] #renomear as colunas: acento, minuscula\n",
    "df.columns = df.columns.str.strip() # Remover espaços em branco dos nomes das colunas\n",
    "df = df.drop(columns=['unnamed: 0', 'valido ate','unnamed: 4' ]) # Remover colunas indesejadas\n",
    "df.rename(columns={'no registrlog': 'reg_log','fator calc':'fat_calc'}, inplace=True)\n",
    "df = df.dropna(how='all') #excluir NaN\n",
    "df['fat_calc'] = df['fat_calc'].str.replace('.', '').str.replace(',', '.').str.strip().astype(float).astype(int)\n",
    "df['fat_calc'].fillna(0, inplace=True)\n",
    "\n",
    "#Evitar duplicação\n",
    "coluna_para_excluir = ['fat_calc']\n",
    "for coluna in coluna_para_excluir:\n",
    "    if coluna in result.columns:\n",
    "        result = result.drop(columns=[coluna])\n",
    "#Combinar dados\n",
    "result = pd.merge(result, df, on='reg_log', how='left')\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for index, row in result.iterrows():\n",
    "    if row['status_cliente'] == 'Ativo' and pd.isna(row['fat_calc']):\n",
    "        result.at[index, 'fat_calc'] = 1\n",
    "        result.at[index, 'tp_medicao'] = 'MD'\n",
    "    elif row['status_cliente'] == 'Ativo' and not(pd.isna(row['fat_calc'])):\n",
    "        result.at[index, 'tp_medicao'] = 'MI'\n",
    "\n",
    "result = result.sort_values(by=['status_cliente','tp_medicao','fat_reg','instalacao']) #ordenar\n",
    "\n",
    "#exportar equipamento lógico para pegar o detalhamento do equipamento\n",
    "export = result[result['status_cliente'] == 'Ativo']['equi_log'].tolist()\n",
    "with open('OUTPUT\\\\equi_log.txt', 'w') as f:\n",
    "    for instalacao in export:\n",
    "        f.write(f\"{instalacao}\\n\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CCS: em_fabri, em_modelo, em_ano, em_material, em_descricao\n",
    "- V_EQUI\n",
    "- WEL_EM\n",
    "- Input equi_log.txt\n",
    "- Salve equi2.txt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Carregar em_fabri, em_modelo, em_ano, em_material, em, em_descricao\n",
    "path = \"C:\\\\Users\\\\u461539\\\\OneDrive - IBERDROLA S.A\\\\005.Scripts\\\\ga_cliente\\\\INPUT\\\\8.equi_log.txt\"\n",
    "df = pd.read_csv(path, delimiter='|', skiprows=3, dtype={'Equipamento       ': str, 'Material': str})\n",
    "df.columns = [unidecode.unidecode(col).lower().replace('.', '') for col in df.columns] #renomear as colunas: acento, minuscula\n",
    "df.columns = df.columns.str.strip() # Remover espaços em branco dos nomes das colunas\n",
    "df = df.drop(columns=['unnamed: 0','unnamed: 8' ]) # Remover colunas indesejadas\n",
    "df.rename(columns={'equipamento':'equi_log','fabricante': 'em_fabri','modelo em': 'em_modelo','anoc':'em_ano','material': 'em_material','no serie':'em','denominacao do objeto tecnico':'em_descricao'}, inplace=True)\n",
    "df = df.dropna(how='all') #excluir NaN\n",
    "df['em_material'] = df['em_material'].str.strip()\n",
    "df['em_fabri'] = df['em_fabri'].str.strip()\n",
    "df['em_modelo'] = df['em_modelo'].str.strip()\n",
    "df['em_material'] = df['em_material'].str.strip()\n",
    "df['em'] = df['em'].str.strip()\n",
    "df['em_descricao'] = df['em_descricao'].str.strip()\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#print(df.head())         # Exibir as primeiras linhas do DataFrame\n",
    "#print(df.columns)\n",
    "#Evitar duplicação\n",
    "coluna_para_excluir = ['em_fabri','em_modelo','em_ano','em_material','em','em_descricao']\n",
    "for coluna in coluna_para_excluir:\n",
    "    if coluna in result.columns:\n",
    "        result = result.drop(columns=[coluna])\n",
    "#Combinar dados\n",
    "result = pd.merge(result, df, on='equi_log', how='left')\n",
    "print(f\"O DataFrame tem {len(result)} linhas. \\n\")\n",
    "\n",
    "nova_ordem_colunas = ['dt_ref', 'instalacao', 'dt_inst_desde', 'ctg_tar', 'set_indus', 'cl_cal', 'mru','mru_status','grupo_cliente','conta_contrato','PN','status_cliente','reg_log','equi_log','em','dt_em_desde','fat_reg','fat_calc','tp_medicao','em_fabri','em_modelo','em_ano','em_material','em_descricao']\n",
    "result = result[nova_ordem_colunas] # Reordenar as colunas do DataFrame\n",
    "result.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "global conn\n",
    "global cursor\n",
    "conn = dbapi.connect(\n",
    "    address=wk.servidor_hana,\n",
    "    port=wk.porta_hana,\n",
    "    user=wk.user_hana,\n",
    "    password=wk.pass_hana,\n",
    "    databasename='BNP',\n",
    "    sslValidateCertificate=False\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "if log:\n",
    "    print('SAP HANA connected')\n",
    "\n",
    "# Executar insert into\n",
    "#wh.hana_insert(result, 'ga_cliente',log)\n",
    "# É mais rápido fazer import pelo DBeaver\n",
    "result.to_csv('OUTPUT\\\\result.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#exportar result\n",
    "print(f\"O DataFrame tem {len(result)} linhas. \\n\")\n",
    "print(result.head())         # Exibir as primeiras linhas do DataFrame\n",
    "print(result.info())         # Exibir as primeiras linhas do DataFrame\n",
    "result.to_csv('OUTPUT\\\\result.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#exportar df\n",
    "print(f\"O DataFrame tem {len(df)} linhas. \\n\")\n",
    "print(df.head())         # Exibir as primeiras linhas do DataFrame\n",
    "print(df.info())         # Exibir as primeiras linhas do DataFrame\n",
    "df.to_csv('OUTPUT\\\\df.csv', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
